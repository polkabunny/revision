Paper link: https://drive.google.com/file/d/0B4T0-Ia20_9ZTFNEVkR6X1dqTkE/view

####Multiple choice
Q1 In trying to predict boxing matches by matching to the nearest exemplar, we have two exemplars:
      
      1. Opponent height - 185cm. Opponent weight - 90kg. Result - I won.
      2. Opponent height - 180cm. Opponent weight - 95kg. Result - I lost.
    
    The question is:
      1. Opponent height - 185cm. Opponent weight - 94kg. Will I win?
    
    We predict by Hamming distance to the nearest exemplar, (a) with height in cm, (b) with height in m. What does it predict?
      1. (a) I win, (b) I lose.
      2. (a) I win, (b) I win.
      3. (a) I lose, (b) I lose.
      4. (a) I lose, (b) I win.

######Answer:
```
    (a) Hamming distance in m -   1. 1 + 4 = 5 -> I win
                                  2. 5 + 1 = 6
    (b) Hamming distance in cm -  1. 0.01 + 4 = 4.01
                                  2. 0.05 + 1 = 1.05 -> I lose
    1. (a) I win, (b) I lose.
```
    
Q2 One of these is not a property of neural networks:
    
    1. It can be used to represent a function from real-valued multi-dimensional input to real-valued multi-dimensional output.
    2. It can be used to represent a function form real-calued single-dimensional input to real-valued single-dimensional output.
    3. It can be used to represent a function from integer-valued multi-dimensional input to integer-valued multi-dimensional output.
    4. Given a network architecture, an Input leads to an Output after a fixed number of calculations.
    5. As learning progresses, the size of the network remains fixed.
    6. Input is compared to previous Input, and "nearby" Input should produce "nearby" Output.
    7. It can be used to represent any normal non-linear, continuous, non-chaotic function.
    8. It can be used to represent any normal linear, continuous, non-chaotic function.

######Answer:
```
    5. As learning progresses, the size of the network remains fixed.
```

Q3 We are learning to represent a function Q(x). The input x is a 100 dimensional vector. Each dimension is an integer from 1 to 10.
   One approach to representing this function would be to have a "lookup table" or array of entries, where we have one entry Q(x) for 
   each input x. This array would be initially blank and we would fill it in by learning. The size of the array is:
   
    1. 10
    2. 100
    3. 110
    4. 1000
    5. 1010
    6. 10 ^ 100
    7. 100 ^ 10

######Answer:
```
    3. 110
```
    
Q4 In machine evolution, our chromosome is a binary string of length n. We interpret it as encoding an integer x. TO convert this to encoding a real number in the interval 0 to 1, we calculate:
    
    1. x / (2 ^ n)
    2. x / (2 ^ (n - 1))
    3. x / (2 ^ (n) - 1)
    4. x / (2 ^ (n - 1) - 1)

######Answer:
```
    3. x / (2 ^ (n) - 1)
```

Q5 In machine evolution, we have 4 individuals, where individual i has fitness f(i):
      
      i     1     2     3     4
      f(i)  0     5     4     5
   
   If we use a "Soft max" probability distribution with a "temperature" parameter T to choose who reproduces, then as T -> 0 the probability of each individual reproducing goes to:
    
    1.      0     1     0     0
    2.      0     1/2   0     1/2
    3.      0     1     0     1
    4.      0     5/14  4/14  5/14 
    5.      0     0.9   0.1   0.9
    6.      1/4   1/4   1/4   1/4
  respectively.

######Answer:
```
    2.      0     1/2   0     1/2
``` 
    
Q6 In a machine evolution run, each individual has 1 set of instructions, encoded in binary format. We repeatedly select 2 parents to make 2 children by copying the 2 sets of instructions with the possibility of mutation and crossover. Let Pc be the probablility that any bit in the instructions mutates when it is inherited. Only one of the following carries out a serious search of the state space. All the others are completely constraned by whatever happens to be the initial population. i.e. Only one of the following can generate all possible genotypes, given enough time.
    
    1. Pm = 1, Pc = 1
    2. Pm = 1, Pc = 0
    3. Pm = 0, Pc = 1
    4. Pm = 0, Pc = 0
    5. Pm = 0.1, Pc = 0

######Answer:
```
    5. Pm = 0.1, Pc = 0
```

Q7 An upper bound on the game-tree complexity of Xs and Os is:
    
    1. 3 ^ 9
    2. 9 ^ 3
    3. 3 ^ 3
    4. 9 ^ 9
    5. 3!
    6. 9!
    
######Answer:
```
    6. 9!
```
  
Q8 An upper bound on the state-space complexity of Xs and Os is:
    
    1. 3 ^ 3
    2. 9 ^ 9
    3. 3 ^ 9
    4. 9 ^ 9
    5. 3!
    6. 9!
######Answer:
```
    3. 3 ^ 9 - 3 states (blank, X, or O to the power of number of squares (9))
```

Q9 With large state-spaces, it is hard to draw the entire state-space representation of a problem. This is solved by:
    
    1. Using a heursitic to reduce the size of the state-space.
    2. Using symmetry to reduce the size of the state-space.
    3. Doing a truncated search.
    4. Writing a program to automatically draw it.
    5. It is not solved. We do not draw the state-space representation of the problem.
    6. We draw a partial state-space representation of the problem.

######Answer:
```
    6. We draw a partial state-space representation of the problem.
```
  
Q10 Imagine the following in Best-first search. The heuristic evaluation function tells us a state is 4 steps away from the goal. We examine the children of this state and the heuristic evaluation function tells us all of them are 5 steps away from the goal. How can this happen?
     
     1. This cannot happen.
     2. This always happens.
     3. We are in an infinite loop.
     4. We are going the wrong way.
     5. The goal has been wrongly defined.
     6. The heuristic evaluation function is inaccurate.
     
######Answer:
```
    6. The heuristic evaluation function is inaccurate.
```
  
