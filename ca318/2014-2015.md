Paper link: https://drive.google.com/file/d/0B4T0-Ia20_9ZaHM2OVlfSU5QaG8/view

####Multiple choice
Q1 The following is a correct ordering of AI methods, from lesser to greater autonomy:
      
      1. Genetic Algorithms, Supervised Learning, Reinforcement Learning.
      2. Genetic Algorithms, Reinforcement Learning, Supervised Learning.
      3. Reinforcement Learning, Genetic Algorithms, Supervised Learning.
      4. Reinforcement Learning, Supervised Learning, Genetic Algorithms.
      5. Supervised Learning, Reinforcement Learning, Genetic Algorithms.
      6. Supervised Learning, Genetic Algorithms, Reinforcement Learning.

######Answer:
```
    5. Supervised Learning, Reinforcement Learning, Genetic Algorithms.
    (Supervised Learning - human must come up with exemplars)
```
    
Q2 Human mate choice is a heuristic because:
      
      1. Humans are not machines.
      2. Humans do not run algorithms.
      3. Humans do not explicitly store all their memories.
      4. Humans do not implicitly store all their memories.
      5. Humans cannot compare different solutions in the search space.
      6. Humans cannot search the entire search space.
      7. Humans cannot search the partial search space.
      8. Humans do not operate according to logic.

######Answer:
```
    6. Humans cannot search the entire search space.
```
    
Q3 Consider a heuristic for human mate choice:

    Have a relationship with n partners of fitness > f
    Marry the next partner you find of fitness > g
   
   where fitness is ranked by the individual out of 10. Which of the following values for n, f, g (respectively) makes the most sense?
      
      1. 10, 0, 8
      2. 10, 5, 8
      3. 10, 8, 3
      4. 0, 0, 8
      5. 0, 5, 8
      6. 0, 8, 3

######Answer:
```
    2. 10, 5, 8
    (Options 4, 5 and 6 -> don't date anyone, makes no sense
    2 -> raise standards
    3 -> drop standards)
```
    
Q4 Which is the correct ordering of these search methods, from the least work for the human programmer to the most work for the human programmer?
      
      1. Domain-specific heuristic, Metaheuristic, Random search
      2. Domain-specific heuristic, Random search, Metaheuristic
      3. Metaheuristic, Domain-specific heuristic, Random search
      4. Metaheuristic, Random search, Domain-specific heuristic
      5. Random search, Domain-specific heuristic, Metaheuristic
      6. Random search, Metaheuristic, Domain-specific heuristic

######Answer:
```
    6. Random search, Metaheuristic, Domain-specific heuristic
    (Random search is the least work, while domain-specific is the most)
```
    
Q5 In trying to predict boxing matches by matching to the nearest exemplar, we have two exemplars:
      
      1. Opponent height - 186cm. Opponent weight - 90kg. Result - I won.
      2. Opponent height - 180cm. Opponent weight - 95kg. Result - I lost.
    
    The question is:
      1. Opponent height - 185cm. Opponent weight - 94kg. Will I win?
    
    We predict by Hamming distance to the nearest exemplar, (a) with height in cm, (b) with height in m. What does it
    predict?
      1. (a) I win, (b) I lose.
      2. (a) I win, (b) I win.
      3. (a) I lose, (b) I lose.
      4. (a) I lose, (b) I win.

######Answer:
```
    (a) Hamming distance in cm -   1. 1 + 4 = 5 -> I win
                                  2. 5 + 1 = 6
    (b) Hamming distance in m -  1. 0.01 + 4 = 4.01
                                  2. 0.05 + 1 = 1.05 -> I lose
    1. (a) I win, (b) I lose.
```
    
Q6 We are learning to represent a function Q(x). The input x is a 10 dimensional vector. Each dimension is an integer from 1 to 100.
   One approach to representing this function would be to have a "lookup table" or array of entries, where we have one entry Q(x) for 
   each input x. This array would be initially blank and we would fill it in by learning. The size of the array is:
   
    1. 10
    2. 100
    3. 110
    4. 1000
    5. 1010
    6. 10 ^ 100
    7. 100 ^ 10

######Answer:
```
    7. 100 ^ 10
    (max input) ^ (number of dimensions)
```
    
Q7 In state-space search, we typically need a function children(x) which can generate the child states of state x. We typically use this function to:
      
      1. Generate a list of the child states of all states.
      2. Generate a graph of the child states of all states.
      3. Generate a list of the child states of most of the states.
      4. Generate a graph of the child states of most of the states.
      5. Generate a list of the child states of a tiny percentage of the states.
      6. Generate a graph of the child states of a tiny percentage of the states.

######Answer:
```
    5. Generate a list of the child states of a tiny percentage of the states.
    (Immediately rule out graphs, porgram doesn't need a visual representation.
    Can only generate for a tiny percentage of the states.)
```
    
Q8 Imagine the following in Best-first search. The heuristic evaluation function tells us a state is 4 steps away from the goal. We examine the children of this state and the heuristic evaluation function tells us all of them are 5 steps away from the goal. How can this happen?
      
      1. This cannot happen.
      2. This always happens.
      3. We are in an infinite loop.
      4. We are going the wrong way.
      5. The goal has been wrongly defined.
      6. The heuristic evaluation function is inaccurate.

######Answer:
```
    6. The heuristic evaluation function is inaccurate.
```
    
Q9 In machine evolution, our chromosome is a binary string of length n. We interpret it as encoding an integer x. To convert this to encoding a real number in the interval a to b, we calculate:
      
      1. x / (2 ^ n)
      2. x / ((2 ^ n) - 1)
      3. a + x (b - a)
      4. a + x / (b - a)
      5. a + (x / ((2 ^ n) - 1) (b - a))
      6. x / (b - a)

######Answer:
```
    5. a + (x / ((2 ^ n) - 1) (b - a))
    (Binary string of length n creates m+ 0 -> (2 ^ n) - 1 = x
    => real number 0 -> 1 => (x/2) - 1 - y
    real number a -> b    => a + y(b - a)
```
    
Q10 In machine evolution, we have 4 individuals, where individual i has fitness f(i):

      i     1     2     3     4
      f(i)  0     -1    -2    -1
      
    If we use a "Soft max probability distribution with a "temperature" paramter T to choose who reproduces, then as
    T -> 0 the probability of each individual reproducing goes to:
      
      1.    0     0     1     0
      2.    0     1     1     1
      3.    0     1/4   1/2   1/4
      4.    0     1/2   0     1/2
      5.    0     1     0     1
      6.    1     0     0     0
      7.    1/4   1/4   1/4   1/4
      
    respectively.

######Answer:
```
    6.    1     0     0     0
```

####Long Questions

Q1 (a)
We do character recognition as follows. Characters are images of 100 x 100 pixels. Each pixel is black or white. We are trying to recognise the digits "0" to "9".

(i) Explain the format of the input and output vectors to the machine.

######Answer:
```
    100^2 boxes, each can take values 0 or 1 - 10,000 inputs
    x = (x1, x2, x3, ... x10000)
    output vector
    y = (y1) -> y1 never takes value 0 to 9
    OR
    y = (y0, y1, ... y9) -> yi takes values 0 or 1 or 0 to 1
```

(ii) How come input vectors are not 2 dimensional?

######Answer:
```
    two dimensional vector does not mean two inputs
    draw picture - no x value, no y value (pixels in space)
    Possible input: http://bit.ly/1NcTWZH
```

(iii) Describe how one would build a machine to predict the class of new, unseen-before images, using a distance metric.

######Answer:
```
    distance metric is definite - which is the exemplar I've seen before that is closest to this one?
    100% answer for closest exemplar
```

(iv) What are the disadvantages of using a distance metric for prediction?

######Answer:
```
    Hamming vs Euclidean difference
    no changing scale - just pixels black/white
    - no previous exemplars at start for comparison
    - more previous exemplars adds processing time
    - happy vs sad face, recognition should recognise only the most important features (privileged pixels)
```

   (b)
A mobile robot has Input state = (angle of direction of nearest wall, velocity value). Output behaviour = one of (turn left, turn right, stop, keep going). What information is the Input state missing? What are the consequences of this missing information?

######Answer:
```
    - distance to the wall - change states depending on distance
    different states appear to be the same state to the machine
    negative impact on behaviour
```

   (c)
We are trying to learn to predict horse races from exemplars. Among our exemplars, we find the following:
      
      The jockey weighed 8 stone. The horse won the race.
      The jockey weighed 8 stone. The horse lost the race.
      
What is going on? How can our exemplars contradict each other? How can the same state lead to a different outcome?

######Answer:
```
    world is in a different state each time
    state we think it's in vs state its actually in

    view multiple different states as the same
      ----------------------------
      | think | actual | outcome |
      ----------------------------
      |   x   |    y   |   win   |
      ----------------------------
      |   x   |    z   |   lose  |
      ----------------------------
    not enough inputs for computer to learn as possible cause
    with inputs from animals/people - unable to predict, inescapable missing input
```

Q2 (a)
Consider a function y = f(x) as follows:
f(1.72) = 55. f(5.63) = 75. f(x) = 0 for all other x.
Why is this function hard to maximise from exemplars?

######Answer:
```
    Every point apart from the defined ones will be (x, 0) - hard to find the defined points
    A slope leading to the points will make them easier to find

    Aside: discontinuous/locally continuous
```
   (b)
Consider a heuristic search as follows:

      1. Initialise with 20 random solutions.
      2. Repeat:
            1. Pick the best 10.
            2. Make small changes in them to generate new pool of 20 candidate solutions.
            3. Loop

Answer the following:

i) Explain what this heuristic is trying to do.

######Answer:
```
    Trying to mutate the solutions randomly - indirect population search
```

ii) Explain how this heuristic may fail.

######Answer:
```
    Peaks in the slope can result in skewing local optimums
```

iii) What would happen if you excluded step 2 in the loop?

######Answer:
```
    You wouldn't get any new solutions after the first run with it excluded
    Including it would keep new solutions
```

iv) In step 1 in the loop, discuss how "Pick the best 1" would compare with "Pick the best 18".

######Answer:
```
    "Pick the best 1"  - leads to only slight variants early on
                   - less diverse as only the best in the first generation would be picked
    "Pick the best 18" - spending too much time on poor solutions that are carried on and modified
                   - best are still carried though
```

   (c)
Consider an algorithm for mate choice as follows:

      if (I am under 25)
            if (fitness of partner > f1) marry them
      else if (I am under 35)
            if (fitness of partner > f2) marry them
      else
            if (fitness of partner > f3) marry them
            
Explain what this algorithm would do. What kind of values would f1, f2 and f3 have?

######Answer:
```

```

   (d)
Explain the concept of a metaheuristic.
######Answer:
```
    A metaheuristic is used to find a sufficiently good solution, with no domain-specific knowledge.
    However it is not random, it uses design patterns and general algorithms that can be applied to a number of 
    problems, so can be used for a variety of problems.
```

######Answer:
```

```
