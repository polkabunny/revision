Paper link: https://drive.google.com/file/d/0B4T0-Ia20_9ZaHM2OVlfSU5QaG8/view

####Multiple choice
Q1 The following is a correct ordering of AI methods, from lesser to greater autonomy:
      
      1. Genetic Algorithms, Supervised Learning, Reinforcement Learning.
      2. Genetic Algorithms, Reinforcement Learning, Supervised Learning.
      3. Reinforcement Learning, Genetic Algorithms, Supervised Learning.
      4. Reinforcement Learning, Supervised Learning, Genetic Algorithms.
      5. Supervised Learning, Reinforcement Learning, Genetic Algorithms.
      6. Supervised Learning, Genetic Algorithms, Reinforcement Learning.

######Answer:
```
    5. Supervised Learning, Reinforcement Learning, Genetic Algorithms.
    (Supervised Learning - human must come up with exemplars)
```
    
Q2 Human mate choice is a heuristic because:
      
      1. Humans are not machines.
      2. Humans do not run algorithms.
      3. Humans do not explicitly store all their memories.
      4. Humans do not implicityly store all their memories.
      5. Humans cannot compare different solutions in the search space.
      6. Humans search the entire search space.
      7. Humans cannot search the partial search space.
      8. Humans do not operate according to logic.

######Answer:
```
    6. Humans search the entire search space.
```
    
Q3 Consider a heuristic for human mate choice:

    Have a relationship with n partners of fitness > f
    Marry the next partner you find of fitness > g
   
   where fitness is ranked by the individual out of 10. Which of the following values for n, f, g (respectively) makes the most sense?
      
      1. 10, 0, 8
      2. 10, 5, 8
      3. 10, 8, 3
      4. 0, 0, 8
      5. 0, 5, 8
      6. 0, 8, 3

######Answer:
```
    2. 10, 5, 8
    (Options 4, 5 and 6 -> don't date anyone, makes no sense
    2 -> raise standards
    3 -> drop standards)
```
    
Q4 Which is the correct ordering of these search methods, from the least work for the human programmer to the most work for the human programmer?
      
      1. Domain-specific heuristic, Metaheuristic, Random search
      2. Domain-specific heuristic, Random search, Metaheuristic
      3. Metaheuristic, Domain-specific heuristic, Random search
      4. Metaheuristic, Random search, Domain-specific heuristic
      5. Random search, Domain-specific heuristic, Metaheuristic
      6. Random search, Metaheuristic, Domain-specific heuristic

######Answer:
```
    6. Random search, Metaheuristic, Domain-specific heuristic
    (Random search is the least work, while domain-specific is the most)
```
    
Q5 In trying to predict boxing matches by matching to the nearest exemplar, we have two exemplars:
      
      1. Opponent height - 186cm. Opponent weight - 90kg. Result - I won.
      2. Opponent height - 180cm. Opponent weight - 95kg. Result - I lost.
    
    The question is:
      1. Opponent height - 185cm. Opponent weight - 94kg. Will I win?
    
    We predict by Hamming distance to the nearest exemplar, (a) with height in cm, (b) with height in m. What does it predict?
      1. (a) I win, (b) I lose.
      2. (a) I win, (b) I win.
      3. (a) I lose, (b) I lose.
      4. (a) I lose, (b) I win.

######Answer:
```
    (a) Hamming distance in cm -   1. 1 + 4 = 5 -> I win
                                  2. 5 + 1 = 6
    (b) Hamming distance in m -  1. 0.01 + 4 = 4.01
                                  2. 0.05 + 1 = 1.05 -> I lose
    1. (a) I win, (b) I lose.
```
    
Q6 We are learning to represent a function Q(x). The input x is a 10 dimensional vector. Each dimension is an integer from 1 to 100.
   One approach to representing this function would be to have a "lookup table" or array of entries, where we have one entry Q(x) for 
   each input x. This array would be initially blank and we would fill it in by learning. The size of the array is:
   
    1. 10
    2. 100
    3. 110
    4. 1000
    5. 1010
    6. 10 ^ 100
    7. 100 ^ 10

######Answer:
```
    7. 100 ^ 10
    (max input) ^ (number of dimensions)
```
    
Q7 In state-space search, we typically need a function children(x) which can generate the child states of state x. We typically use this function to:
      
      1.Generate a list of the child states of all states.
      2. Generate a graph of the child states of all states.
      3. Generate a list of the child states of most of the states.
      4. Generate a graph of the child states of most of the states.
      5. Generate a list of the child states of a tiny percentage of the states.
      6. Generate a graph of the child states of a tiny percentage of the states.

######Answer:
```
    5. Generate a list of the child states of a tiny percentage of the states.
    (Immediately rule out graphs, porgram doesn't need a visual representation.
    Can only generate for a tiny percentage of the states.)
```
    
Q8 Imagine the following in Best-first search. The heuristic evaluation function tells us a state is 4 steps away from the goal. We examine the children of this state an the heuristic evaluation function tells us all of them are 5 steps away from the goal. How can this happen?
      
      1. This cannot happen.
      2. This always happens.
      3. We are in an infinite loop.
      4. We are going the wrong way.
      5. The goal has been wrongly defined.
      6. The heuristic evaluation function is inaccurate.

######Answer:
```
    6. The heuristic evaluation function is inaccurate.
```
    
Q9 In machine evolution, our chromosome is a binary string of length n. We interpret it as encoding an integer x. TO convert this to encoding a real number in the interval a to b, we calculate:
      
      1. x / (2 ^ n)
      2. x / ((2 ^ n) - 1)
      3. a + x (b - a)
      4. a + x / (b - a)
      5. a + (x / ((2 ^ n) - 1) (b - a))
      6. x / (b - a)

######Answer:
```
    5. a + (x / ((2 ^ n) - 1) (b - a))
    (Binary string of length n creates m+ 0 -> (2 ^ n) - 1 = x
    => real number 0 -> 1 => (x/2) - 1 - y
    real number a -> b    => a + y(b - a)
```
    
Q10 In machine evolution, we have 4 individuals, where individual i has fitness f(i):

      i     1     2     3     4
      f(i)  0     -1    -2    -1
      
    If we use a "Soft max probability distribution with a "temperature" paramter T to choose who reproduces,m then as T -> 0 the probability of each individual reproducing goes to:
      
      1.    0     0     1     0
      2.    0     1     1     1
      3.    0     1/4   1/2   1/4
      4.    0     1/2   0     1/2
      5.    0     1     0     1
      6.    1     0     0     0
      7.    1/4   1/4   1/4   1/4
      
    respectively.

######Answer:
```
    6.    1     0     0     0
```
    
Q 
      
      1. 

######Answer:
```
    
```
    
